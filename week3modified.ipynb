{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>position</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>level1_labels</th>\n",
       "      <th>level2_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>https://www.bbc.com/news/entertainment_and_arts</td>\n",
       "      <td>Entertainment &amp; Arts - BBC News</td>\n",
       "      <td>Get the latest BBC Entertainment and Arts news...</td>\n",
       "      <td>Entertainment &amp; Arts - BBC News Get the latest...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>https://www.champaigncounty.org/list/ql/arts-c...</td>\n",
       "      <td>Arts, Culture &amp; Entertainment | Champaign Coun...</td>\n",
       "      <td>Champaign County Chamber of Commerce - IL 303 ...</td>\n",
       "      <td>Arts, Culture &amp; Entertainment | Champaign Coun...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>https://www.bls.gov/oes/current/oes270000.htm</td>\n",
       "      <td>Arts, Design, Entertainment, Sports, and Media...</td>\n",
       "      <td>27-0000 Arts, Design, Entertainment, Sports, a...</td>\n",
       "      <td>Arts, Design, Entertainment, Sports, and Media...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>https://www.smc.edu/academics/areas-of-interes...</td>\n",
       "      <td>Arts, Media, &amp; Entertainment - Santa Monica Co...</td>\n",
       "      <td>Let your imagination run wild and free — explo...</td>\n",
       "      <td>Arts, Media, &amp; Entertainment - Santa Monica Co...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>https://illinois.edu/arts/</td>\n",
       "      <td>Arts &amp; Culture | University of Illinois Urbana...</td>\n",
       "      <td>Arts &amp; Culture. From the nation’s premier perf...</td>\n",
       "      <td>Arts &amp; Culture | University of Illinois Urbana...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  position                                   query  \\\n",
       "0           0         1  arts, culture, entertainment and media   \n",
       "1           1         2  arts, culture, entertainment and media   \n",
       "2           2         3  arts, culture, entertainment and media   \n",
       "3           3         4  arts, culture, entertainment and media   \n",
       "4           4         5  arts, culture, entertainment and media   \n",
       "\n",
       "                                                 url  \\\n",
       "0    https://www.bbc.com/news/entertainment_and_arts   \n",
       "1  https://www.champaigncounty.org/list/ql/arts-c...   \n",
       "2      https://www.bls.gov/oes/current/oes270000.htm   \n",
       "3  https://www.smc.edu/academics/areas-of-interes...   \n",
       "4                         https://illinois.edu/arts/   \n",
       "\n",
       "                                               title  \\\n",
       "0                    Entertainment & Arts - BBC News   \n",
       "1  Arts, Culture & Entertainment | Champaign Coun...   \n",
       "2  Arts, Design, Entertainment, Sports, and Media...   \n",
       "3  Arts, Media, & Entertainment - Santa Monica Co...   \n",
       "4  Arts & Culture | University of Illinois Urbana...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  Get the latest BBC Entertainment and Arts news...   \n",
       "1  Champaign County Chamber of Commerce - IL 303 ...   \n",
       "2  27-0000 Arts, Design, Entertainment, Sports, a...   \n",
       "3  Let your imagination run wild and free — explo...   \n",
       "4  Arts & Culture. From the nation’s premier perf...   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  Entertainment & Arts - BBC News Get the latest...   \n",
       "1  Arts, Culture & Entertainment | Champaign Coun...   \n",
       "2  Arts, Design, Entertainment, Sports, and Media...   \n",
       "3  Arts, Media, & Entertainment - Santa Monica Co...   \n",
       "4  Arts & Culture | University of Illinois Urbana...   \n",
       "\n",
       "                            level1_labels level2_labels  \n",
       "0  arts, culture, entertainment and media           NaN  \n",
       "1  arts, culture, entertainment and media           NaN  \n",
       "2  arts, culture, entertainment and media           NaN  \n",
       "3  arts, culture, entertainment and media           NaN  \n",
       "4  arts, culture, entertainment and media           NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"data.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor_final2(text):\n",
    "    if isinstance((text), (str)):\n",
    "        text = re.sub('<[^>]*>', ' ', text)\n",
    "        text = re.sub('[\\W]+', ' ', text.lower())\n",
    "        return text\n",
    "    if isinstance((text), (list)):\n",
    "        return_list = []\n",
    "        for i in range(len(text)):\n",
    "            temp_text = re.sub('<[^>]*>', '', text[i])\n",
    "            temp_text = re.sub('[\\W]+', '', temp_text.lower())\n",
    "            return_list.append(temp_text)\n",
    "        return(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['combined_text'] = data['combined_text'] .apply(preprocessor_final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['combined_text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "online media                 18\n",
       "Mennonite                    10\n",
       "shipbuilding                 10\n",
       "organic food                 10\n",
       "sport shooting               10\n",
       "                             ..\n",
       "department store              2\n",
       "long distance run             2\n",
       "synchronised free routine     2\n",
       "biotechnology business        2\n",
       "flying disc                   1\n",
       "Name: query, Length: 1296, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['query'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport                                        2476\n",
       "economy, business and finance                1976\n",
       "politics                                      779\n",
       "arts, culture, entertainment and media        557\n",
       "crime, law and justice                        489\n",
       "health                                        465\n",
       "science and technology                        435\n",
       "religion and belief                           434\n",
       "lifestyle and leisure                         420\n",
       "society                                       414\n",
       "labour                                        271\n",
       "disaster, accident and emergency incident     244\n",
       "conflict, war and peace                       232\n",
       "environment                                   229\n",
       "education                                     202\n",
       "human interest                                146\n",
       "weather                                        43\n",
       "Name: level1_labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['level1_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'arts and entertainment', 'culture', 'mass media',\n",
       "       'economic sector', 'act of terror', 'armed conflict',\n",
       "       'civil unrest', \"coup d'etat\", 'massacre', 'peace process',\n",
       "       'post-war reconstruction', 'prisoners of war', 'crime',\n",
       "       'judiciary', 'justice', 'law', 'law enforcement',\n",
       "       'accident and emergency incident', 'disaster',\n",
       "       'emergency incident', 'emergency planning', 'emergency response',\n",
       "       'business information', 'economy', 'market and exchange',\n",
       "       'parent organisation', 'religious education', 'school',\n",
       "       'social learning', 'teaching and learning', 'vocational education',\n",
       "       'climate change', 'conservation', 'environmental politics',\n",
       "       'environmental pollution', 'natural resources', 'nature',\n",
       "       'diseases and conditions', 'health facility',\n",
       "       'health organisations', 'health treatment', 'healthcare policy',\n",
       "       'medical profession', 'non-human diseases', 'accomplishment',\n",
       "       'animal', 'anniversary', 'ceremony', 'people', 'plant',\n",
       "       'employment', 'employment legislation', 'labour market',\n",
       "       'labour relations', 'retirement', 'unemployment', 'unions',\n",
       "       'exercise and fitness', 'leisure', 'lifestyle', 'election',\n",
       "       'fundamental rights', 'government', 'government policy',\n",
       "       'international relations', 'non-governmental organisation',\n",
       "       'political crisis', 'political dissent', 'political process',\n",
       "       'interreligious dialogue', 'religious belief',\n",
       "       'religious conflict', 'religious event', 'religious facilities',\n",
       "       'religious institutions and state relations', 'religious leader',\n",
       "       'religious text', 'biomedical science', 'mathematics',\n",
       "       'natural science', 'scientific institution', 'scientific research',\n",
       "       'scientific standards', 'social sciences',\n",
       "       'technology and engineering', 'communities', 'demographics',\n",
       "       'discrimination', 'emigration', 'family', 'immigration', 'mankind',\n",
       "       'social condition', 'social problem', 'values', 'welfare',\n",
       "       'bodybuilding', 'competition discipline',\n",
       "       'disciplinary action in sport', 'drug use in sport', 'sport event',\n",
       "       'sport industry', 'sport organisation', 'sport venue', 'transfer',\n",
       "       'weather forecast', 'weather phenomena', 'weather statistic',\n",
       "       'weather warning'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['level2_labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "         return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "     return [porter.stem(word) for word in text.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query as label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "text_count_2 = tfidf.fit_transform(data['combined_text'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2, data['query'],test_size=0.25,random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "SGDC = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_sgdc = 68.16%\n",
      "recall_macro_score_sgdc = 63.08%\n",
      "recall_micro_score_sgdc = 68.16%\n",
      "recall_weighted_score_sgdc = 68.16%\n",
      "f1_macro_score_sgdc = 61.42%\n",
      "f1_micro_score_sgdc = 68.16%\n",
      "f1_weighted_score_sgdc = 70.27%\n",
      "Precision_macro_score_sgdc = 66.26%\n",
      "Precision_micro_score_sgdc = 68.16%\n",
      "Precision_weighted_score_sgdc = 80.46%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "recall_mac_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "recall_mic_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "recall_weighted_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "f1_mac_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "f1_mic_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "f1_weighted_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "pre_mac_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "pre_mic_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "pre_weighted_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "print('recall_macro_score_sgdc = '+str('{:4.2f}'.format(recall_mac_score_sgdc*100))+'%')\n",
    "print('recall_micro_score_sgdc = '+str('{:4.2f}'.format(recall_mic_score_sgdc*100))+'%')\n",
    "print('recall_weighted_score_sgdc = '+str('{:4.2f}'.format(recall_weighted_score_sgdc*100))+'%')\n",
    "print('f1_macro_score_sgdc = '+str('{:4.2f}'.format(f1_mac_score_sgdc*100))+'%')\n",
    "print('f1_micro_score_sgdc = '+str('{:4.2f}'.format(f1_mic_score_sgdc*100))+'%')\n",
    "print('f1_weighted_score_sgdc = '+str('{:4.2f}'.format(f1_weighted_score_sgdc*100))+'%')\n",
    "print('Precision_macro_score_sgdc = '+str('{:4.2f}'.format(pre_mac_score_sgdc*100))+'%')\n",
    "print('Precision_micro_score_sgdc = '+str('{:4.2f}'.format(pre_mic_score_sgdc*100))+'%')\n",
    "print('Precision_weighted_score_sgdc = '+str('{:4.2f}'.format(pre_weighted_score_sgdc*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[A-Za-z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(data['combined_text'])\n",
    "x_train,x_test,y_train,y_test = train_test_split(text_counts, data['query'], test_size=0.25, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_sgdc_cv = 54.67%\n",
      "accuracy_score_sgdc = 68.16%\n",
      "recall_macro_score_sgdc = 52.08%\n",
      "recall_micro_score_sgdc = 54.67%\n",
      "recall_weighted_score_sgdc = 54.67%\n",
      "f1_macro_score_sgdc = 49.35%\n",
      "f1_micro_score_sgdc = 54.67%\n",
      "f1_weighted_score_sgdc = 56.10%\n",
      "Precision_macro_score_sgdc = 52.90%\n",
      "Precision_micro_score_sgdc = 54.67%\n",
      "Precision_weighted_score_sgdc = 69.70%\n"
     ]
    }
   ],
   "source": [
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')\n",
    "recall_mac_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "recall_mic_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "recall_weighted_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "f1_mac_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "f1_mic_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "f1_weighted_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "pre_mac_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "pre_mic_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "pre_weighted_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "print('recall_macro_score_sgdc = '+str('{:4.2f}'.format(recall_mac_score_sgdc*100))+'%')\n",
    "print('recall_micro_score_sgdc = '+str('{:4.2f}'.format(recall_mic_score_sgdc*100))+'%')\n",
    "print('recall_weighted_score_sgdc = '+str('{:4.2f}'.format(recall_weighted_score_sgdc*100))+'%')\n",
    "print('f1_macro_score_sgdc = '+str('{:4.2f}'.format(f1_mac_score_sgdc*100))+'%')\n",
    "print('f1_micro_score_sgdc = '+str('{:4.2f}'.format(f1_mic_score_sgdc*100))+'%')\n",
    "print('f1_weighted_score_sgdc = '+str('{:4.2f}'.format(f1_weighted_score_sgdc*100))+'%')\n",
    "print('Precision_macro_score_sgdc = '+str('{:4.2f}'.format(pre_mac_score_sgdc*100))+'%')\n",
    "print('Precision_micro_score_sgdc = '+str('{:4.2f}'.format(pre_mic_score_sgdc*100))+'%')\n",
    "print('Precision_weighted_score_sgdc = '+str('{:4.2f}'.format(pre_weighted_score_sgdc*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Level 1 Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "text_count_2 = tfidf.fit_transform(data['combined_text'])\n",
    "\n",
    "#splitting the data in test and training\n",
    "#from sklearn.model_selection() import train_test_split()\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2, data['level1_labels'],test_size=0.25,random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "SGDC = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_sgdc = 87.04%\n",
      "accuracy_score_sgdc = 87.04%\n",
      "recall_macro_score_sgdc = 86.45%\n",
      "recall_micro_score_sgdc = 87.04%\n",
      "recall_weighted_score_sgdc = 87.04%\n",
      "f1_macro_score_sgdc = 84.36%\n",
      "f1_micro_score_sgdc = 87.04%\n",
      "f1_weighted_score_sgdc = 87.19%\n",
      "Precision_macro_score_sgdc = 83.20%\n",
      "Precision_micro_score_sgdc = 87.04%\n",
      "Precision_weighted_score_sgdc = 87.66%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "recall_mac_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "recall_mic_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "recall_weighted_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "f1_mac_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "f1_mic_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "f1_weighted_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "pre_mac_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "pre_mic_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "pre_weighted_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "print('recall_macro_score_sgdc = '+str('{:4.2f}'.format(recall_mac_score_sgdc*100))+'%')\n",
    "print('recall_micro_score_sgdc = '+str('{:4.2f}'.format(recall_mic_score_sgdc*100))+'%')\n",
    "print('recall_weighted_score_sgdc = '+str('{:4.2f}'.format(recall_weighted_score_sgdc*100))+'%')\n",
    "print('f1_macro_score_sgdc = '+str('{:4.2f}'.format(f1_mac_score_sgdc*100))+'%')\n",
    "print('f1_micro_score_sgdc = '+str('{:4.2f}'.format(f1_mic_score_sgdc*100))+'%')\n",
    "print('f1_weighted_score_sgdc = '+str('{:4.2f}'.format(f1_weighted_score_sgdc*100))+'%')\n",
    "print('Precision_macro_score_sgdc = '+str('{:4.2f}'.format(pre_mac_score_sgdc*100))+'%')\n",
    "print('Precision_micro_score_sgdc = '+str('{:4.2f}'.format(pre_mic_score_sgdc*100))+'%')\n",
    "print('Precision_weighted_score_sgdc = '+str('{:4.2f}'.format(pre_weighted_score_sgdc*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[A-Za-z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(data['combined_text'])\n",
    "x_train,x_test,y_train,y_test = train_test_split(text_counts, data['level1_labels'], test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_sgdc_cv = 85.00%\n",
      "accuracy_score_sgdc_cv = 85.00%\n",
      "accuracy_score_sgdc = 87.04%\n",
      "recall_macro_score_sgdc = 82.88%\n",
      "recall_micro_score_sgdc = 85.00%\n",
      "recall_weighted_score_sgdc = 85.00%\n",
      "f1_macro_score_sgdc = 81.58%\n",
      "f1_micro_score_sgdc = 85.00%\n",
      "f1_weighted_score_sgdc = 85.07%\n",
      "Precision_macro_score_sgdc = 80.51%\n",
      "Precision_micro_score_sgdc = 85.00%\n",
      "Precision_weighted_score_sgdc = 85.29%\n"
     ]
    }
   ],
   "source": [
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')\n",
    "accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')\n",
    "recall_mac_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "recall_mic_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "recall_weighted_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "f1_mac_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "f1_mic_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "f1_weighted_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "pre_mac_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "pre_mic_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "pre_weighted_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "print('recall_macro_score_sgdc = '+str('{:4.2f}'.format(recall_mac_score_sgdc*100))+'%')\n",
    "print('recall_micro_score_sgdc = '+str('{:4.2f}'.format(recall_mic_score_sgdc*100))+'%')\n",
    "print('recall_weighted_score_sgdc = '+str('{:4.2f}'.format(recall_weighted_score_sgdc*100))+'%')\n",
    "print('f1_macro_score_sgdc = '+str('{:4.2f}'.format(f1_mac_score_sgdc*100))+'%')\n",
    "print('f1_micro_score_sgdc = '+str('{:4.2f}'.format(f1_mic_score_sgdc*100))+'%')\n",
    "print('f1_weighted_score_sgdc = '+str('{:4.2f}'.format(f1_weighted_score_sgdc*100))+'%')\n",
    "print('Precision_macro_score_sgdc = '+str('{:4.2f}'.format(pre_mac_score_sgdc*100))+'%')\n",
    "print('Precision_micro_score_sgdc = '+str('{:4.2f}'.format(pre_mic_score_sgdc*100))+'%')\n",
    "print('Precision_weighted_score_sgdc = '+str('{:4.2f}'.format(pre_weighted_score_sgdc*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['level2_labels'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Level2 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "text_count_2 = tfidf.fit_transform(data2['combined_text'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2, data2['level2_labels'],test_size=0.25,random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "SGDC = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_sgdc = 82.04%\n",
      "accuracy_score_sgdc = 82.04%\n",
      "recall_macro_score_sgdc = 79.74%\n",
      "recall_micro_score_sgdc = 82.04%\n",
      "recall_weighted_score_sgdc = 82.04%\n",
      "f1_macro_score_sgdc = 72.45%\n",
      "f1_micro_score_sgdc = 82.04%\n",
      "f1_weighted_score_sgdc = 82.79%\n",
      "Precision_macro_score_sgdc = 69.78%\n",
      "Precision_micro_score_sgdc = 82.04%\n",
      "Precision_weighted_score_sgdc = 85.17%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "recall_mac_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "recall_mic_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "recall_weighted_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "f1_mac_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "f1_mic_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "f1_weighted_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "pre_mac_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "pre_mic_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "pre_weighted_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "print('recall_macro_score_sgdc = '+str('{:4.2f}'.format(recall_mac_score_sgdc*100))+'%')\n",
    "print('recall_micro_score_sgdc = '+str('{:4.2f}'.format(recall_mic_score_sgdc*100))+'%')\n",
    "print('recall_weighted_score_sgdc = '+str('{:4.2f}'.format(recall_weighted_score_sgdc*100))+'%')\n",
    "print('f1_macro_score_sgdc = '+str('{:4.2f}'.format(f1_mac_score_sgdc*100))+'%')\n",
    "print('f1_micro_score_sgdc = '+str('{:4.2f}'.format(f1_mic_score_sgdc*100))+'%')\n",
    "print('f1_weighted_score_sgdc = '+str('{:4.2f}'.format(f1_weighted_score_sgdc*100))+'%')\n",
    "print('Precision_macro_score_sgdc = '+str('{:4.2f}'.format(pre_mac_score_sgdc*100))+'%')\n",
    "print('Precision_micro_score_sgdc = '+str('{:4.2f}'.format(pre_mic_score_sgdc*100))+'%')\n",
    "print('Precision_weighted_score_sgdc = '+str('{:4.2f}'.format(pre_weighted_score_sgdc*100))+'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[A-Za-z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(data2['combined_text'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_counts, data2['level2_labels'], test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_sgdc_cv = 79.19%\n",
      "accuracy_score_sgdc = 82.04%\n",
      "recall_macro_score_sgdc = 68.21%\n",
      "recall_micro_score_sgdc = 79.19%\n",
      "recall_weighted_score_sgdc = 79.19%\n",
      "f1_macro_score_sgdc = 64.64%\n",
      "f1_micro_score_sgdc = 79.19%\n",
      "f1_weighted_score_sgdc = 78.40%\n",
      "Precision_macro_score_sgdc = 67.13%\n",
      "Precision_micro_score_sgdc = 79.19%\n",
      "Precision_weighted_score_sgdc = 80.12%\n"
     ]
    }
   ],
   "source": [
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')\n",
    "recall_mac_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "recall_mic_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "recall_weighted_score_sgdc = metrics.recall_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "f1_mac_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "f1_mic_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "f1_weighted_score_sgdc = metrics.f1_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "pre_mac_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='macro')\n",
    "pre_mic_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='micro')\n",
    "pre_weighted_score_sgdc = metrics.precision_score(SGDC.predict(x_test), y_test,average='weighted')\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "print('recall_macro_score_sgdc = '+str('{:4.2f}'.format(recall_mac_score_sgdc*100))+'%')\n",
    "print('recall_micro_score_sgdc = '+str('{:4.2f}'.format(recall_mic_score_sgdc*100))+'%')\n",
    "print('recall_weighted_score_sgdc = '+str('{:4.2f}'.format(recall_weighted_score_sgdc*100))+'%')\n",
    "print('f1_macro_score_sgdc = '+str('{:4.2f}'.format(f1_mac_score_sgdc*100))+'%')\n",
    "print('f1_micro_score_sgdc = '+str('{:4.2f}'.format(f1_mic_score_sgdc*100))+'%')\n",
    "print('f1_weighted_score_sgdc = '+str('{:4.2f}'.format(f1_weighted_score_sgdc*100))+'%')\n",
    "print('Precision_macro_score_sgdc = '+str('{:4.2f}'.format(pre_mac_score_sgdc*100))+'%')\n",
    "print('Precision_micro_score_sgdc = '+str('{:4.2f}'.format(pre_mic_score_sgdc*100))+'%')\n",
    "print('Precision_weighted_score_sgdc = '+str('{:4.2f}'.format(pre_weighted_score_sgdc*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data[data['level2_labels'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilable Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using only label 1 and label 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>position</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>level1_labels</th>\n",
       "      <th>level2_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>https://www.aetv.com/</td>\n",
       "      <td>A&amp;E | Watch Full Episodes of Your Favorite Shows</td>\n",
       "      <td>Stream full episodes of A&amp;E series, including ...</td>\n",
       "      <td>a e watch full episodes of your favorite shows...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>arts and entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>https://www.aetv.com/shows</td>\n",
       "      <td>A&amp;E TV Shows | A&amp;E</td>\n",
       "      <td>Check out A&amp;E's shows lineup. Find show info, ...</td>\n",
       "      <td>a e tv shows a e check out a e s shows lineup ...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>arts and entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>https://www.bbc.com/news/entertainment_and_arts</td>\n",
       "      <td>Entertainment &amp; Arts - BBC News</td>\n",
       "      <td>Get the latest BBC Entertainment and Arts news...</td>\n",
       "      <td>entertainment arts bbc news get the latest bbc...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>arts and entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>https://www.news-gazette.com/arts-entertainment/</td>\n",
       "      <td>Arts &amp; Entertainment | news-gazette.com</td>\n",
       "      <td>· Cloudy. Snow showers developing late. Low 2...</td>\n",
       "      <td>arts entertainment news gazette com cloudy sno...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>arts and entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>https://www.theguardian.com/us/culture</td>\n",
       "      <td>Arts and entertainment news from Guardian US |...</td>\n",
       "      <td>The Oscar-tipped Netflix drama centers on a ha...</td>\n",
       "      <td>arts and entertainment news from guardian us t...</td>\n",
       "      <td>arts, culture, entertainment and media</td>\n",
       "      <td>arts and entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10756</th>\n",
       "      <td>10756</td>\n",
       "      <td>6</td>\n",
       "      <td>weather warning</td>\n",
       "      <td>https://weather.com/weather/alerts/localalerts...</td>\n",
       "      <td>Champaign, IL Weather Alerts - The Weather Cha...</td>\n",
       "      <td>Quick access to active weather alerts througho...</td>\n",
       "      <td>champaign il weather alerts the weather channe...</td>\n",
       "      <td>weather</td>\n",
       "      <td>weather warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10757</th>\n",
       "      <td>10757</td>\n",
       "      <td>7</td>\n",
       "      <td>weather warning</td>\n",
       "      <td>https://www.weather.gov/ilx/</td>\n",
       "      <td>Central Illinois - National Weather Service</td>\n",
       "      <td>· Snow in the Northeast; High Winds and Criti...</td>\n",
       "      <td>central illinois national weather service snow...</td>\n",
       "      <td>weather</td>\n",
       "      <td>weather warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10758</th>\n",
       "      <td>10758</td>\n",
       "      <td>8</td>\n",
       "      <td>weather warning</td>\n",
       "      <td>https://www.spc.noaa.gov/products/wwa/</td>\n",
       "      <td>NWS - Watch, Warning, Advisory Display</td>\n",
       "      <td>· Ice Storm Warning Winter Weather Advisory: ...</td>\n",
       "      <td>nws watch warning advisory display ice storm w...</td>\n",
       "      <td>weather</td>\n",
       "      <td>weather warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10759</th>\n",
       "      <td>10759</td>\n",
       "      <td>9</td>\n",
       "      <td>weather warning</td>\n",
       "      <td>https://alerts.weather.gov/cap/ca.php?x=1</td>\n",
       "      <td>Current Watches, Warnings and Advisories for C...</td>\n",
       "      <td>Current Watches, Warnings and Advisories for C...</td>\n",
       "      <td>current watches warnings and advisories for ca...</td>\n",
       "      <td>weather</td>\n",
       "      <td>weather warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10760</th>\n",
       "      <td>10760</td>\n",
       "      <td>10</td>\n",
       "      <td>weather warning</td>\n",
       "      <td>https://alerts.weather.gov/cap/us.php?x=1</td>\n",
       "      <td>Current Watches, Warnings and Advisories for t...</td>\n",
       "      <td>WINTER WEATHER ADVISORY IN EFFECT FROM 5 PM TH...</td>\n",
       "      <td>current watches warnings and advisories for th...</td>\n",
       "      <td>weather</td>\n",
       "      <td>weather warning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9665 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  position                   query  \\\n",
       "10             10         1  arts and entertainment   \n",
       "11             11         2  arts and entertainment   \n",
       "12             12         3  arts and entertainment   \n",
       "13             13         4  arts and entertainment   \n",
       "14             14         5  arts and entertainment   \n",
       "...           ...       ...                     ...   \n",
       "10756       10756         6         weather warning   \n",
       "10757       10757         7         weather warning   \n",
       "10758       10758         8         weather warning   \n",
       "10759       10759         9         weather warning   \n",
       "10760       10760        10         weather warning   \n",
       "\n",
       "                                                     url  \\\n",
       "10                                 https://www.aetv.com/   \n",
       "11                            https://www.aetv.com/shows   \n",
       "12       https://www.bbc.com/news/entertainment_and_arts   \n",
       "13      https://www.news-gazette.com/arts-entertainment/   \n",
       "14                https://www.theguardian.com/us/culture   \n",
       "...                                                  ...   \n",
       "10756  https://weather.com/weather/alerts/localalerts...   \n",
       "10757                       https://www.weather.gov/ilx/   \n",
       "10758             https://www.spc.noaa.gov/products/wwa/   \n",
       "10759          https://alerts.weather.gov/cap/ca.php?x=1   \n",
       "10760          https://alerts.weather.gov/cap/us.php?x=1   \n",
       "\n",
       "                                                   title  \\\n",
       "10      A&E | Watch Full Episodes of Your Favorite Shows   \n",
       "11                                    A&E TV Shows | A&E   \n",
       "12                       Entertainment & Arts - BBC News   \n",
       "13               Arts & Entertainment | news-gazette.com   \n",
       "14     Arts and entertainment news from Guardian US |...   \n",
       "...                                                  ...   \n",
       "10756  Champaign, IL Weather Alerts - The Weather Cha...   \n",
       "10757        Central Illinois - National Weather Service   \n",
       "10758             NWS - Watch, Warning, Advisory Display   \n",
       "10759  Current Watches, Warnings and Advisories for C...   \n",
       "10760  Current Watches, Warnings and Advisories for t...   \n",
       "\n",
       "                                                 snippet  \\\n",
       "10     Stream full episodes of A&E series, including ...   \n",
       "11     Check out A&E's shows lineup. Find show info, ...   \n",
       "12     Get the latest BBC Entertainment and Arts news...   \n",
       "13      · Cloudy. Snow showers developing late. Low 2...   \n",
       "14     The Oscar-tipped Netflix drama centers on a ha...   \n",
       "...                                                  ...   \n",
       "10756  Quick access to active weather alerts througho...   \n",
       "10757   · Snow in the Northeast; High Winds and Criti...   \n",
       "10758   · Ice Storm Warning Winter Weather Advisory: ...   \n",
       "10759  Current Watches, Warnings and Advisories for C...   \n",
       "10760  WINTER WEATHER ADVISORY IN EFFECT FROM 5 PM TH...   \n",
       "\n",
       "                                           combined_text  \\\n",
       "10     a e watch full episodes of your favorite shows...   \n",
       "11     a e tv shows a e check out a e s shows lineup ...   \n",
       "12     entertainment arts bbc news get the latest bbc...   \n",
       "13     arts entertainment news gazette com cloudy sno...   \n",
       "14     arts and entertainment news from guardian us t...   \n",
       "...                                                  ...   \n",
       "10756  champaign il weather alerts the weather channe...   \n",
       "10757  central illinois national weather service snow...   \n",
       "10758  nws watch warning advisory display ice storm w...   \n",
       "10759  current watches warnings and advisories for ca...   \n",
       "10760  current watches warnings and advisories for th...   \n",
       "\n",
       "                                level1_labels           level2_labels  \n",
       "10     arts, culture, entertainment and media  arts and entertainment  \n",
       "11     arts, culture, entertainment and media  arts and entertainment  \n",
       "12     arts, culture, entertainment and media  arts and entertainment  \n",
       "13     arts, culture, entertainment and media  arts and entertainment  \n",
       "14     arts, culture, entertainment and media  arts and entertainment  \n",
       "...                                       ...                     ...  \n",
       "10756                                 weather         weather warning  \n",
       "10757                                 weather         weather warning  \n",
       "10758                                 weather         weather warning  \n",
       "10759                                 weather         weather warning  \n",
       "10760                                 weather         weather warning  \n",
       "\n",
       "[9665 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "text_count_2 = tfidf.fit_transform(data2['combined_text'])\n",
    "y=np.asarray(data2[data2.columns[7:]])\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2,y,test_size=0.25,random_state=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_Logistic  = 57.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_macro_score= 72.90%\n",
      "recall_micro_score= 93.23%\n",
      "recall_weighted_score = 93.23%\n",
      "f1_macro_score= 53.95%\n",
      "f1_micro_score = 78.35%\n",
      "f1_weighted_score= 81.22%\n",
      "Precision_macro_score= 45.48%\n",
      "Precision_micro_score= 67.56%\n",
      "Precision_weighted_score= 73.60%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "nbClassifier = OneVsRestClassifier(SGDClassifier())\n",
    "nbClassifier.fit(x_train,y_train)\n",
    "nbpred = nbClassifier.predict(x_test)\n",
    "accuracy_score_nbc = metrics.accuracy_score(nbpred, y_test)\n",
    "print('accuracy_score_Logistic  = '+str('{:4.2f}'.format(accuracy_score_nbc*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(nbpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(nbpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(nbpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(nbpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(nbpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(nbpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(nbpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(nbpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(nbpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_KNN = 13.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_macro_score= 3.66%\n",
      "recall_micro_score= 98.04%\n",
      "recall_weighted_score = 98.04%\n",
      "f1_macro_score= 1.48%\n",
      "f1_micro_score = 28.32%\n",
      "f1_weighted_score= 73.09%\n",
      "Precision_macro_score= 1.16%\n",
      "Precision_micro_score= 16.55%\n",
      "Precision_weighted_score= 60.24%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "nbClassifier = OneVsRestClassifier(MultinomialNB())\n",
    "nbClassifier.fit(x_train,y_train)\n",
    "nbpred = nbClassifier.predict(x_test)\n",
    "accuracy_score_nbc = metrics.accuracy_score(nbpred, y_test)\n",
    "print('accuracy_score_KNN = '+str('{:4.2f}'.format(accuracy_score_nbc*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(nbpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(nbpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(nbpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(nbpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(nbpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(nbpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(nbpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(nbpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(nbpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_KNN = 73.89%\n",
      "recall_macro_score= 75.94%\n",
      "recall_micro_score= 90.76%\n",
      "recall_weighted_score = 90.76%\n",
      "f1_macro_score= 65.76%\n",
      "f1_micro_score = 83.70%\n",
      "f1_weighted_score= 84.67%\n",
      "Precision_macro_score= 60.80%\n",
      "Precision_micro_score= 77.66%\n",
      "Precision_weighted_score= 80.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnClf = KNeighborsClassifier()\n",
    "\n",
    "knnClf.fit(x_train, y_train)\n",
    "knnpred = knnClf.predict(x_test)\n",
    "\n",
    "accuracy_score_KNN = metrics.accuracy_score(knnpred, y_test)\n",
    "print('accuracy_score_KNN = '+str('{:4.2f}'.format(accuracy_score_KNN*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(knnpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(knnpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(knnpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(knnpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(knnpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(knnpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(knnpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(knnpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(knnpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_DTC = 41.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_macro_score= 28.32%\n",
      "recall_micro_score= 47.84%\n",
      "recall_weighted_score = 47.84%\n",
      "f1_macro_score= 24.77%\n",
      "f1_micro_score = 47.74%\n",
      "f1_weighted_score= 49.03%\n",
      "Precision_macro_score= 24.67%\n",
      "Precision_micro_score= 47.64%\n",
      "Precision_weighted_score= 51.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)\n",
    "dtcpred = dtc.predict(x_test)\n",
    "accuracy_score_dtc= metrics.accuracy_score(dtcpred, y_test)\n",
    "print('accuracy_score_DTC = '+str('{:4.2f}'.format(accuracy_score_dtc*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(dtcpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(dtcpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(dtcpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(dtcpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(dtcpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(dtcpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(dtcpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(dtcpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(dtcpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_RFC = 23.71%\n",
      "recall_macro_score= 26.87%\n",
      "recall_micro_score= 88.40%\n",
      "recall_weighted_score = 88.40%\n",
      "f1_macro_score= 7.40%\n",
      "f1_micro_score = 45.46%\n",
      "f1_weighted_score= 68.95%\n",
      "Precision_macro_score= 5.06%\n",
      "Precision_micro_score= 30.60%\n",
      "Precision_weighted_score= 61.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(x_train, y_train)\n",
    "rfcpred = rfc.predict(x_test)\n",
    "accuracy_score_rfc = metrics.accuracy_score(rfcpred, y_test)\n",
    "print('accuracy_score_RFC = '+str('{:4.2f}'.format(accuracy_score_rfc*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(rfcpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(rfcpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(rfcpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(rfcpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(rfcpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(rfcpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(rfcpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(rfcpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(rfcpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_KNN = 43.07%\n",
      "recall_macro_score= 65.85%\n",
      "recall_micro_score= 82.09%\n",
      "recall_weighted_score = 82.09%\n",
      "f1_macro_score= 54.26%\n",
      "f1_micro_score = 70.52%\n",
      "f1_weighted_score= 72.31%\n",
      "Precision_macro_score= 48.11%\n",
      "Precision_micro_score= 61.81%\n",
      "Precision_weighted_score= 65.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "bagc= OneVsRestClassifier(BaggingClassifier(n_jobs=-1))\n",
    "bagc.fit(x_train, y_train)\n",
    "bagcpred = bagc.predict(x_test)\n",
    "\n",
    "accuracy_score_bagc = metrics.accuracy_score(bagcpred, y_test)\n",
    "print('accuracy_score_KNN = '+str('{:4.2f}'.format(accuracy_score_bagc*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(bagcpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(bagcpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(bagcpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(bagcpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(bagcpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(bagcpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(bagcpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(bagcpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(bagcpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using query, label 1 and label 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['arts and entertainment' 'arts, culture, entertainment and media'\n",
      "  'arts and entertainment']\n",
      " ['arts and entertainment' 'arts, culture, entertainment and media'\n",
      "  'arts and entertainment']\n",
      " ['arts and entertainment' 'arts, culture, entertainment and media'\n",
      "  'arts and entertainment']\n",
      " ...\n",
      " ['weather warning' 'weather' 'weather warning']\n",
      " ['weather warning' 'weather' 'weather warning']\n",
      " ['weather warning' 'weather' 'weather warning']]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "text_count_2 = tfidf.fit_transform(data2['combined_text'])\n",
    "array=[2,7,8]\n",
    "y=np.asarray(data2[data2.columns[array]])\n",
    "print(y)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "print(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2,y,test_size=0.25,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 471 is present in all training examples.\n",
      "  warnings.warn(\"Label %s is present in all training examples.\" %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_Logistic  = 23.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_macro_score= 36.17%\n",
      "recall_micro_score= 92.84%\n",
      "recall_weighted_score = 92.84%\n",
      "f1_macro_score= 29.22%\n",
      "f1_micro_score = 68.50%\n",
      "f1_weighted_score= 80.64%\n",
      "Precision_macro_score= 26.36%\n",
      "Precision_micro_score= 54.28%\n",
      "Precision_weighted_score= 73.34%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "nbClassifier = OneVsRestClassifier(SGDClassifier())\n",
    "nbClassifier.fit(x_train,y_train)\n",
    "nbpred = nbClassifier.predict(x_test)\n",
    "accuracy_score_nbc = metrics.accuracy_score(nbpred, y_test)\n",
    "print('accuracy_score_Logistic  = '+str('{:4.2f}'.format(accuracy_score_nbc*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(nbpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(nbpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(nbpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(nbpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(nbpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(nbpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(nbpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(nbpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(nbpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 471 is present in all training examples.\n",
      "  warnings.warn(\"Label %s is present in all training examples.\" %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_NB = 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_macro_score= 0.36%\n",
      "recall_micro_score= 98.04%\n",
      "recall_weighted_score = 98.04%\n",
      "f1_macro_score= 0.14%\n",
      "f1_micro_score = 20.34%\n",
      "f1_weighted_score= 73.09%\n",
      "Precision_macro_score= 0.11%\n",
      "Precision_micro_score= 11.35%\n",
      "Precision_weighted_score= 60.24%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "nbClassifier = OneVsRestClassifier(MultinomialNB())\n",
    "nbClassifier.fit(x_train,y_train)\n",
    "nbpred = nbClassifier.predict(x_test)\n",
    "accuracy_score_nbc = metrics.accuracy_score(nbpred, y_test)\n",
    "print('accuracy_score_NB = '+str('{:4.2f}'.format(accuracy_score_nbc*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(nbpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(nbpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(nbpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(nbpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(nbpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(nbpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(nbpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(nbpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(nbpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_KNN = 47.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_macro_score= 52.66%\n",
      "recall_micro_score= 89.59%\n",
      "recall_weighted_score = 89.59%\n",
      "f1_macro_score= 47.07%\n",
      "f1_micro_score = 77.37%\n",
      "f1_weighted_score= 83.62%\n",
      "Precision_macro_score= 45.61%\n",
      "Precision_micro_score= 68.09%\n",
      "Precision_weighted_score= 80.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnClf = KNeighborsClassifier()\n",
    "knnClf.fit(x_train, y_train)\n",
    "knnpred = knnClf.predict(x_test)\n",
    "\n",
    "accuracy_score_KNN = metrics.accuracy_score(knnpred, y_test)\n",
    "print('accuracy_score_KNN = '+str('{:4.2f}'.format(accuracy_score_KNN*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(knnpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(knnpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(knnpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(knnpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(knnpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(knnpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(knnpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(knnpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(knnpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_DTC = 16.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_macro_score= 16.86%\n",
      "recall_micro_score= 39.90%\n",
      "recall_weighted_score = 39.90%\n",
      "f1_macro_score= 14.86%\n",
      "f1_micro_score = 39.59%\n",
      "f1_weighted_score= 40.57%\n",
      "Precision_macro_score= 16.35%\n",
      "Precision_micro_score= 39.29%\n",
      "Precision_weighted_score= 43.83%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)\n",
    "dtcpred = dtc.predict(x_test)\n",
    "accuracy_score_dtc= metrics.accuracy_score(dtcpred, y_test)\n",
    "print('accuracy_score_DTC = '+str('{:4.2f}'.format(accuracy_score_dtc*100))+'%')\n",
    "recall_mac_score = metrics.recall_score(dtcpred, y_test,average='macro')\n",
    "recall_mic_score = metrics.recall_score(dtcpred, y_test,average='micro')\n",
    "recall_weighted_score= metrics.recall_score(dtcpred, y_test,average='weighted')\n",
    "f1_mac_score = metrics.f1_score(dtcpred, y_test,average='macro')\n",
    "f1_mic_score = metrics.f1_score(dtcpred, y_test,average='micro')\n",
    "f1_weighted_score= metrics.f1_score(dtcpred, y_test,average='weighted')\n",
    "pre_mac_score= metrics.precision_score(dtcpred, y_test,average='macro')\n",
    "pre_mic_score = metrics.precision_score(dtcpred, y_test,average='micro')\n",
    "pre_weighted_score = metrics.precision_score(dtcpred, y_test,average='weighted')\n",
    "print('recall_macro_score= '+str('{:4.2f}'.format(recall_mac_score*100))+'%')\n",
    "print('recall_micro_score= '+str('{:4.2f}'.format(recall_mic_score*100))+'%')\n",
    "print('recall_weighted_score = '+str('{:4.2f}'.format(recall_weighted_score*100))+'%')\n",
    "print('f1_macro_score= '+str('{:4.2f}'.format(f1_mac_score*100))+'%')\n",
    "print('f1_micro_score = '+str('{:4.2f}'.format(f1_mic_score*100))+'%')\n",
    "print('f1_weighted_score= '+str('{:4.2f}'.format(f1_weighted_score*100))+'%')\n",
    "print('Precision_macro_score= '+str('{:4.2f}'.format(pre_mac_score*100))+'%')\n",
    "print('Precision_micro_score= '+str('{:4.2f}'.format(pre_mic_score*100))+'%')\n",
    "print('Precision_weighted_score= '+str('{:4.2f}'.format(pre_weighted_score*100))+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
